{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatsath/Interpretability/blob/main/logit_lens_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng49HHFSi60S"
      },
      "source": [
        "# Logit Lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4WjMrRNi9Mm"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKMviqeei-0Y"
      },
      "source": [
        "ðŸ” Logit Lens is a powerful tool that grants us a simplified (yet insightful) understanding of the inner workings of transformer models.\n",
        "\n",
        "We can estimate the model's guess for the output after each computational step by applying a softmax function to each layer's output. Unlike traditional approaches focusing on *how* beliefs are updated within a step, with Logit Lens we gain a glimpse into *what* output the model is predicting at each processing step.\n",
        "\n",
        "ðŸ“— Read more about Logit Lens from nostalgebraistâ€™s blog post on LessWrong, [here](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)\n",
        "\n",
        "ðŸ’» You can find a Colab version of our tutorial [here](https://colab.research.google.com/github/ndif-team/nnsight/blob/main/docs/source/notebooks/tutorials/logit_lens.ipynb), or nostalgebraistâ€™s original code [here](https://colab.research.google.com/drive/1-nOE-Qyia3ElM17qrdoHAtGmLCPUZijg?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktwAplz6jP1v"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YO08TbUN8Su"
      },
      "source": [
        "If using Colab, install NNsight:\n",
        "```\n",
        "!pip install -U nnsight\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJV-o-XpN8Su",
        "outputId": "6c8df4f9-2ad2-441f-8fa9-c8507dc88601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nnsight in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from nnsight) (4.48.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from nnsight) (4.25.6)\n",
            "Requirement already satisfied: python-socketio[client] in /usr/local/lib/python3.11/dist-packages (from nnsight) (5.12.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.21.0)\n",
            "Requirement already satisfied: pydantic>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from nnsight) (2.10.6)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from nnsight) (2.5.1+cu124)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.20.1+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from nnsight) (1.3.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.32.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.8.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.19.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from nnsight) (0.10.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from nnsight) (7.34.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.0->nnsight) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.0->nnsight) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.0->nnsight) (4.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.0->nnsight) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->nnsight) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->nnsight) (1.3.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate->nnsight) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->nnsight) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->nnsight) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->nnsight) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->nnsight) (0.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->nnsight) (8.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers->nnsight) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers->nnsight) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers->nnsight) (11.1.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->nnsight) (4.9.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]->nnsight) (0.23.1)\n",
            "Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]->nnsight) (4.11.2)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]->nnsight) (1.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->nnsight) (4.67.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->nnsight) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->nnsight) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nnsight) (0.2.13)\n",
            "Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio[client]->nnsight) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->nnsight) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->nnsight) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->nnsight) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->nnsight) (2025.1.31)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->nnsight) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->nnsight) (3.0.2)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio[client]->nnsight) (1.2.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio[client]->nnsight) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    is_colab = True\n",
        "except ImportError:\n",
        "    is_colab = False\n",
        "\n",
        "if is_colab:\n",
        "    !pip install -U nnsight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkMbHYsn7ofy"
      },
      "source": [
        "Import libraries and load GPT-2 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "_VsZHFh7Fi4X"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from IPython.display import clear_output\n",
        "from nnsight import LanguageModel\n",
        "from typing import List, Callable\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Kv4b1dGYjYNh"
      },
      "outputs": [],
      "source": [
        "# Load gpt2\n",
        "model = LanguageModel(\"openai-community/gpt2\", device_map=\"auto\", dispatch=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFeJgNv1jZDf"
      },
      "source": [
        "## GPT-2 Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULg0CFgO9gbp"
      },
      "source": [
        "Let's take a look at GPT-2's architecture. GPT-2 has 12 layers, accessed as `model.transformer.h`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "bzSdXMcTjhgx"
      },
      "outputs": [],
      "source": [
        "#print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfqTBHq-jiKu"
      },
      "source": [
        "## Apply Logit Lens\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJYqMa3V-B2w"
      },
      "source": [
        "To apply logit lens, we collect activations at each layer's output, apply layer normalization (`model.transformer.ln_f`), and then process through the model's head (`model.lm_head`) to get the logits. Next, we apply the softmax to the logits to obtain output token probabilities.\n",
        "\n",
        "By observing different layers' output token probabilities, logit lens provides insights into the model's confidence throughout processing steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "a2OkUOXQjmHL"
      },
      "outputs": [],
      "source": [
        "#prompt= \"The Eiffel Tower is in the city of\"\n",
        "prompt= \"With good earnings the stock price of company will likely\"\n",
        "#prompt= \"With the Federal Reserve raising interest rates, the bond market is expected to\"\n",
        "layers = model.transformer.h\n",
        "probs_layers = []\n",
        "probs_attn_layers = []\n",
        "probs_mlp_layers = []\n",
        "\n",
        "with model.trace() as tracer:\n",
        "    with tracer.invoke(prompt) as invoker:\n",
        "        for layer_idx, layer in enumerate(layers):\n",
        "            # Process layer output through the model's head and layer normalization\n",
        "            layer_output = model.lm_head(model.transformer.ln_f(layer.output[0]))\n",
        "\n",
        "            # Apply softmax to obtain probabilities and save the result\n",
        "            probs = torch.nn.functional.softmax(layer_output, dim=-1).save()\n",
        "            probs_layers.append(probs)\n",
        "\n",
        "            # Get attention output and process\n",
        "            attn_output = model.lm_head(model.transformer.ln_f(layer.attn.output[0]))\n",
        "            probs_attn = torch.nn.functional.softmax(attn_output, dim=-1).save()\n",
        "            probs_attn_layers.append(probs_attn)\n",
        "\n",
        "             # Get mlp output and process\n",
        "            mlp_output = model.lm_head(model.transformer.ln_f(layer.mlp.output[0]))\n",
        "            probs_mlp = torch.nn.functional.softmax(mlp_output, dim=-1).save()\n",
        "            probs_mlp_layers.append(probs_mlp)\n",
        "\n",
        "probs = torch.cat([probs.value for probs in probs_layers])\n",
        "probs_attn = torch.cat([probs.value for probs in probs_attn_layers])\n",
        "probs_mlp = torch.cat([probs.value for probs in probs_mlp_layers])\n",
        "\n",
        "# Find the maximum probability and corresponding tokens for each position\n",
        "max_probs, tokens = probs.max(dim=-1)\n",
        "\n",
        "# Decode token IDs to words for each layer\n",
        "words = [[model.tokenizer.decode(t.cpu()).encode(\"unicode_escape\").decode() for t in layer_tokens]\n",
        "    for layer_tokens in tokens]\n",
        "\n",
        "# Access the 'input_ids' attribute of the invoker object to get the input words\n",
        "input_words = [model.tokenizer.decode(t) for t in invoker.inputs[0][0][\"input_ids\"][0]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# probs_layers"
      ],
      "metadata": {
        "id": "TJ-V6E7sS_R7"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probs_attn"
      ],
      "metadata": {
        "id": "QTJFYc_ofg1h"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUHM9SWQVmob"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcFbmC1XjoQ2"
      },
      "source": [
        "## Visualizing GPT-2 Layer Interpretations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoclUIRzjrY2"
      },
      "source": [
        "Now we will visualize the prediction of the GPT-2 model and weâ€™ll explore the interpretations of each layer within the GPT2Block, gaining insights into what each layer believes could be the next word for every input word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "hdzaJn2xVDue",
        "outputId": "aee8a36c-e2ed-4196-ec37-d95b3cb11bae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"af601c7b-478e-4f42-a6e7-7761d575591c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"af601c7b-478e-4f42-a6e7-7761d575591c\")) {                    Plotly.newPlot(                        \"af601c7b-478e-4f42-a6e7-7761d575591c\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{text}\",\"x\":[\"With\",\" good\",\" earnings\",\" the\",\" stock\",\" price\",\" of\",\" company\",\" will\",\" likely\"],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11],\"z\":[[0.13976984,0.32165757,0.9888439,0.41001442,0.8386183,0.98808366,0.5638406,0.58131963,0.5533041,0.69607425],[0.09506563,0.6558652,0.98261845,0.71033436,0.6369756,0.96045244,0.6795197,0.25519508,0.68385625,0.38393837],[0.031070514,0.59480625,0.96556515,0.7403094,0.4197403,0.68378633,0.77297235,0.13283572,0.6724773,0.11145438],[0.031075394,0.5938099,0.9420727,0.41702384,0.73960346,0.5806925,0.65720797,0.63371676,0.59873074,0.37675044],[0.030536948,0.5654349,0.94343436,0.23700775,0.8745041,0.7468152,0.5525202,0.22940122,0.6804104,0.6621351],[0.029863615,0.4956591,0.8092889,0.20366937,0.8326384,0.53594184,0.6365636,0.70696044,0.7581459,0.6934618],[0.029488774,0.78736305,0.83460647,0.09597421,0.85664266,0.50413084,0.4718369,0.89156383,0.75265837,0.6968548],[0.029348897,0.94528687,0.6590086,0.32708755,0.571185,0.42053515,0.21811926,0.38552245,0.5793441,0.84981006],[0.029405912,0.96185887,0.27019015,0.5739178,0.41591343,0.15220629,0.5023772,0.2936077,0.32172915,0.34617132],[0.02962515,0.78177685,0.32475415,0.77844363,0.37435108,0.32807377,0.26429987,0.67766535,0.58185655,0.2531755],[0.03015221,0.44554746,0.31778952,0.47531468,0.2315344,0.2554389,0.24984176,0.28377444,0.6742569,0.5275478],[0.0987079,0.16426083,0.35086098,0.13593866,0.18665855,0.17631157,0.15612723,0.15226111,0.14430168,0.15859932]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Input Tokens: %{x}\\u003cbr\\u003eLayers: %{y}\\u003cbr\\u003eProbability: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"text\":[[\" the\",\" good\",\" earnings\",\" same\",\" stock\",\" price\",\" the\",\" company\",\" be\",\" likely\"],[\" the\",\" enough\",\" earnings\",\" same\",\" stock\",\" price\",\" the\",\" company\",\" be\",\" likely\"],[\" the\",\" enough\",\" earnings\",\" same\",\" market\",\" price\",\" the\",\"'s\",\" be\",\" likely\"],[\" the\",\" enough\",\" earnings\",\" same\",\"holders\",\" price\",\" the\",\"wide\",\" be\",\" be\"],[\" the\",\" news\",\" earnings\",\" same\",\"holders\",\" price\",\" the\",\"wide\",\" be\",\" be\"],[\" the\",\" news\",\" earnings\",\" entire\",\"holders\",\" price\",\" the\",\"wide\",\" be\",\" be\"],[\" the\",\" luck\",\" earnings\",\" fastest\",\"holders\",\" price\",\" the\",\"wide\",\" be\",\" be\"],[\" the\",\" luck\",\" earnings\",\" company\",\"holders\",\" price\",\" the\",\"wide\",\" be\",\" be\"],[\" the\",\" luck\",\" growth\",\" company\",\" market\",\" rose\",\" the\",\" shares\",\" rise\",\" be\"],[\" the\",\" luck\",\" growth\",\" company\",\" market\",\" rose\",\" Bitcoin\",\" shares\",\" rise\",\" decline\"],[\" the\",\" reason\",\",\",\" company\",\" has\",\" rose\",\" the\",\" shares\",\" rise\",\" rise\"],[\" the\",\" reason\",\",\",\" company\",\" has\",\" has\",\" the\",\" shares\",\" rise\",\" rise\"]]}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Input Tokens\"},\"tickangle\":0},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layers\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Probability\"}},\"colorscale\":[[0.0,\"rgb(49,54,149)\"],[0.1,\"rgb(69,117,180)\"],[0.2,\"rgb(116,173,209)\"],[0.3,\"rgb(171,217,233)\"],[0.4,\"rgb(224,243,248)\"],[0.5,\"rgb(255,255,191)\"],[0.6,\"rgb(254,224,144)\"],[0.7,\"rgb(253,174,97)\"],[0.8,\"rgb(244,109,67)\"],[0.9,\"rgb(215,48,39)\"],[1.0,\"rgb(165,0,38)\"]],\"cmid\":0.5},\"margin\":{\"t\":60},\"title\":{\"text\":\"Logit Lens Visualization\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('af601c7b-478e-4f42-a6e7-7761d575591c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "if is_colab:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n",
        "\n",
        "fig = px.imshow(\n",
        "    max_probs.detach().cpu().numpy(),\n",
        "    x=input_words,\n",
        "    y=list(range(len(words))),\n",
        "    color_continuous_scale=px.colors.diverging.RdYlBu_r,\n",
        "    color_continuous_midpoint=0.50,\n",
        "    text_auto=True,\n",
        "    labels=dict(x=\"Input Tokens\", y=\"Layers\", color=\"Probability\")\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Logit Lens Visualization',\n",
        "    xaxis_tickangle=0\n",
        ")\n",
        "\n",
        "fig.update_traces(text=words, texttemplate=\"%{text}\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "saqU-fjXgQjk"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7-5TdX2j6V2"
      },
      "source": [
        "The vertical axis indexes the layers, zero-indexed from 0 to 11. The top guess for each token, according to the modelâ€™s activations at a given layer, is printed in each cell. The colors show the probability associated with the top guess."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import plotly.express as px\n",
        "# import plotly.io as pio\n",
        "# import torch\n",
        "# from plotly.subplots import make_subplots\n",
        "# import plotly.graph_objects as go\n",
        "\n",
        "# if is_colab:\n",
        "#     pio.renderers.default = \"colab\"\n",
        "# else:\n",
        "#     pio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n",
        "\n",
        "# num_layers = len(probs_layers)\n",
        "# num_input_words = len(input_words)\n",
        "\n",
        "# fig = make_subplots(rows=num_layers, cols=1, subplot_titles=[f\"Layer {i}\" for i in range(num_layers)])\n",
        "\n",
        "\n",
        "# for layer_idx, layer_probs in enumerate(probs_layers):\n",
        "#     layer_probs = layer_probs.value.detach().cpu().numpy() # Use .value to get the tensor's value\n",
        "\n",
        "#     # Get the token ids\n",
        "#     all_tokens = list(range(layer_probs.shape[-1]))\n",
        "\n",
        "#     # Reshape the layer probabilities to have input words as rows and token ids as columns.\n",
        "#     layer_probs_reshaped = layer_probs.transpose(1,0,2).reshape(num_input_words, -1)\n",
        "\n",
        "\n",
        "#     fig.add_trace(go.Heatmap(z=layer_probs_reshaped,\n",
        "#                             x=[model.tokenizer.decode(t).encode(\"unicode_escape\").decode() for t in all_tokens],\n",
        "#                             y=input_words,\n",
        "#                             colorscale=px.colors.diverging.RdYlBu_r,\n",
        "#                             zmid=0.5,\n",
        "#                             ),\n",
        "#                   row=layer_idx+1, col=1)\n",
        "\n",
        "# fig.update_layout(height=300*num_layers, title_text=\"Logit Lens Visualization - All Tokens per Layer\",\n",
        "#                    xaxis_tickangle=0)\n",
        "# fig.update_xaxes(tickangle=45)\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "yJI--xbuVnX2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from IPython.display import clear_output\n",
        "from nnsight import LanguageModel\n",
        "from typing import List, Callable\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "# %%\n",
        "# Load gpt2\n",
        "model = LanguageModel(\"openai-community/gpt2\", device_map=\"auto\", dispatch=True)\n",
        "# %% [markdown]\n",
        "# ## GPT-2 Model Architecture\n",
        "# %% [markdown]\n",
        "# Let's take a look at GPT-2's architecture. GPT-2 has 12 layers, accessed as `model.transformer.h`.\n",
        "# %%\n",
        "# print(model)\n",
        "# %% [markdown]\n",
        "# ## Apply Logit Lens\n",
        "#\n",
        "#\n",
        "# %% [markdown]\n",
        "# To apply logit lens, we collect activations at each layer's output, apply layer normalization (`model.transformer.ln_f`), and then process through the model's head (`model.lm_head`) to get the logits. Next, we apply the softmax to the logits to obtain output token probabilities.\n",
        "#\n",
        "# By observing different layers' output token probabilities, logit lens provides insights into the model's confidence throughout processing steps.\n",
        "# %%\n",
        "# Define the financial prompt\n",
        "prompt= \"With good earnings the stock price of company will likely\"\n",
        "# define the words for which we will compare the logits\n",
        "logit_words = [\"rise\", \"fall\"]\n",
        "layers = model.transformer.h\n",
        "probs_layers = []\n",
        "logits_layers = []\n",
        "\n",
        "with model.trace() as tracer:\n",
        "    with tracer.invoke(prompt) as invoker:\n",
        "        for layer_idx, layer in enumerate(layers):\n",
        "            # Process layer output through the model's head and layer normalization\n",
        "            layer_output = model.lm_head(model.transformer.ln_f(layer.output[0]))\n",
        "\n",
        "            # Apply softmax to obtain probabilities and save the result\n",
        "            probs = torch.nn.functional.softmax(layer_output, dim=-1).save()\n",
        "            probs_layers.append(probs)\n",
        "            logits_layers.append(layer_output.save())\n",
        "\n",
        "\n",
        "probs = torch.cat([probs.value for probs in probs_layers])\n",
        "logits = torch.cat([logits.value for logits in logits_layers])\n",
        "\n",
        "# Find the maximum probability and corresponding tokens for each position\n",
        "max_probs, tokens = probs.max(dim=-1)\n",
        "\n",
        "\n",
        "# Decode token IDs to words for each layer\n",
        "words = [[model.tokenizer.decode(t.cpu()).encode(\"unicode_escape\").decode() for t in layer_tokens]\n",
        "    for layer_tokens in tokens]\n",
        "\n",
        "# Access the 'input_ids' attribute of the invoker object to get the input words\n",
        "input_words = [model.tokenizer.decode(t) for t in invoker.inputs[0][0][\"input_ids\"][0]]\n",
        "\n",
        "# Get Logits for specified words\n",
        "logit_tokens = [model.tokenizer.encode(word)[0] for word in logit_words]\n",
        "logit_values = logits[:,:,logit_tokens]\n",
        "\n",
        "# Calculate logit difference between the two words\n",
        "logit_diff = logit_values[:,:,0] - logit_values[:,:,1]\n",
        "\n",
        "# Average the logit difference across all input tokens for each layer\n",
        "avg_logit_diff_per_layer = torch.mean(logit_diff, dim=1)\n",
        "# %%\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "if is_colab:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n",
        "\n",
        "fig = go.Figure(data=[go.Bar(x=list(range(len(avg_logit_diff_per_layer))), y=avg_logit_diff_per_layer.detach().cpu().numpy())])\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Average Logit Difference Between 'rise' and 'fall' Per Layer\",\n",
        "    xaxis_title=\"Layer\",\n",
        "    yaxis_title=\"Average Logit Difference (rise - fall)\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "rclopAKKzIUw",
        "outputId": "61b0216c-ed38-4e0b-9bf1-c7dffe7bf7dd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a2aa89ae-1799-43ba-86e6-cb255c0ece80\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a2aa89ae-1799-43ba-86e6-cb255c0ece80\")) {                    Plotly.newPlot(                        \"a2aa89ae-1799-43ba-86e6-cb255c0ece80\",                        [{\"x\":[0,1,2,3,4,5,6,7,8,9,10,11],\"y\":[-3.2208576,-2.1618316,-2.1983972,-1.9705925,-1.1029074,-1.106133,-0.98528767,0.8717219,2.056128,3.0120106,2.1012516,0.4272476],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Average Logit Difference Between 'rise' and 'fall' Per Layer\"},\"xaxis\":{\"title\":{\"text\":\"Layer\"}},\"yaxis\":{\"title\":{\"text\":\"Average Logit Difference (rise - fall)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a2aa89ae-1799-43ba-86e6-cb255c0ece80');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}