{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5O8tQblzOVHu"
   },
   "source": [
    "# Training a basic SAE with SAELens\n",
    "\n",
    "This tutorial demonstrates training a simple, relatively small Sparse Autoencoder, specifically on the tiny-stories-1L-21M model. \n",
    "\n",
    "As the SAELens library is under active development, please open an issue if this tutorial is stale [here](https://github.com/jbloomAus/SAELens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shAFb9-lOVHu"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "id": "LeRi_tw2dhae",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sae-lens\n",
      "  Using cached sae_lens-5.4.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting transformer-lens\n",
      "  Using cached transformer_lens-2.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting circuitsvis\n",
      "  Using cached circuitsvis-1.43.3-py3-none-any.whl.metadata (983 bytes)\n",
      "Collecting automated-interpretability<1.0.0,>=0.0.5 (from sae-lens)\n",
      "  Using cached automated_interpretability-0.0.7-py3-none-any.whl.metadata (829 bytes)\n",
      "Collecting babe<0.0.8,>=0.0.7 (from sae-lens)\n",
      "  Using cached babe-0.0.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting datasets<3.0.0,>=2.17.1 (from sae-lens)\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from sae-lens) (3.10.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from sae-lens) (0.1.7)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from sae-lens)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting plotly<6.0.0,>=5.19.0 (from sae-lens)\n",
      "  Using cached plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting plotly-express<0.5.0,>=0.4.1 (from sae-lens)\n",
      "  Using cached plotly_express-0.4.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pytest-profiling<2.0.0,>=1.7.0 (from sae-lens)\n",
      "  Using cached pytest_profiling-1.8.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from sae-lens)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from sae-lens) (6.0.2)\n",
      "Collecting pyzmq==26.0.0 (from sae-lens)\n",
      "  Using cached pyzmq-26.0.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (6.2 kB)\n",
      "Collecting safetensors<0.5.0,>=0.4.2 (from sae-lens)\n",
      "  Using cached safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting simple-parsing<0.2.0,>=0.1.6 (from sae-lens)\n",
      "  Using cached simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.1 (from sae-lens)\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting typer<0.13.0,>=0.12.3 (from sae-lens)\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from sae-lens) (4.12.2)\n",
      "Collecting zstandard<0.23.0,>=0.22.0 (from sae-lens)\n",
      "  Using cached zstandard-0.22.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting accelerate>=0.23.0 (from transformer-lens)\n",
      "  Using cached accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens)\n",
      "  Using cached beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer-lens)\n",
      "  Using cached better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting einops>=0.6.0 (from transformer-lens)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer-lens)\n",
      "  Using cached fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jaxtyping>=0.2.11 (from transformer-lens)\n",
      "  Using cached jaxtyping-0.2.38-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from transformer-lens) (2.2.3)\n",
      "Collecting pandas>=1.1.5 (from transformer-lens)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting rich>=12.6.0 (from transformer-lens)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentencepiece (from transformer-lens)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting torch<2.5,>=2.2 (from transformer-lens)\n",
      "  Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting tqdm>=4.64.1 (from transformer-lens)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer-lens)\n",
      "  Using cached transformers_stream_generator-0.0.5-py3-none-any.whl\n",
      "Collecting typeguard<5.0,>=4.2 (from transformer-lens)\n",
      "  Using cached typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wandb>=0.13.5 (from transformer-lens)\n",
      "  Using cached wandb-0.19.6-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting importlib-metadata>=5.1.0 (from circuitsvis)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (7.0.0)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.23.0->transformer-lens)\n",
      "  Using cached huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting blobfile<3.0.0,>=2.1.1 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached blobfile-2.1.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting boostedblob<0.16.0,>=0.15.3 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached boostedblob-0.15.6-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting numpy>=1.24 (from transformer-lens)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting orjson<4.0.0,>=3.10.1 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached orjson-3.10.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting scikit-learn<2.0.0,>=1.2.0 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting tiktoken<0.7.0,>=0.6.0 (from automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting py2store (from babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Using cached py2store-0.1.20-py3-none-any.whl\n",
      "Collecting graze (from babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Using cached graze-0.1.29-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting filelock (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached pyarrow-19.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.32.3)\n",
      "Collecting xxhash (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached aiohttp-3.11.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=5.1.0->circuitsvis)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer-lens)\n",
      "  Using cached wadler_lindig-0.1.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.9.0.post0)\n",
      "Requirement already satisfied: traitlets in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.14.3)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->sae-lens)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->sae-lens)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->sae-lens)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.5->transformer-lens)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.5->transformer-lens)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly<6.0.0,>=5.19.0->sae-lens)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting statsmodels>=0.9.0 (from plotly-express<0.5.0,>=0.4.1->sae-lens)\n",
      "  Using cached statsmodels-0.14.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting scipy>=0.18 (from plotly-express<0.5.0,>=0.4.1->sae-lens)\n",
      "  Using cached scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting patsy>=0.5 (from plotly-express<0.5.0,>=0.4.1->sae-lens)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.17.0)\n",
      "Collecting pytest (from pytest-profiling<2.0.0,>=1.7.0->sae-lens)\n",
      "  Using cached pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting gprof2dot (from pytest-profiling<2.0.0,>=1.7.0->sae-lens)\n",
      "  Using cached gprof2dot-2024.6.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.6.0->transformer-lens)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens) (2.19.1)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing<0.2.0,>=0.1.6->sae-lens)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch<2.5,>=2.2->transformer-lens)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch<2.5,>=2.2->transformer-lens)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from torch<2.5,>=2.2->transformer-lens) (3.1.5)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.38.1->sae-lens)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.13.0,>=0.12.3->sae-lens)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (4.3.6)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pydantic<3,>=2.6 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached sentry_sdk-2.21.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached setproctitle-1.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (65.5.0)\n",
      "Collecting pycryptodomex~=3.8 (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached pycryptodomex-3.21.0-cp36-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.3.0)\n",
      "Collecting lxml~=4.9 (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached lxml-4.9.4-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting uvloop>=0.16.0 (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.14.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens) (3.4.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn<2.0.0,>=1.2.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dol (from graze->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Using cached dol-0.3.9-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tatsa/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from jinja2->torch<2.5,>=2.2->transformer-lens) (3.0.2)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets<3.0.0,>=2.17.1->sae-lens)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting config2py (from py2store->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Using cached config2py-0.1.36-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting importlib_resources (from py2store->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting iniconfig (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch<2.5,>=2.2->transformer-lens)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting i2 (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Using cached i2-0.1.46-py3-none-any.whl.metadata (2.1 kB)\n",
      "Using cached sae_lens-5.4.2-py3-none-any.whl (125 kB)\n",
      "Using cached pyzmq-26.0.0-cp311-cp311-macosx_10_15_universal2.whl (1.4 MB)\n",
      "Using cached transformer_lens-2.14.0-py3-none-any.whl (183 kB)\n",
      "Using cached circuitsvis-1.43.3-py3-none-any.whl (1.8 MB)\n",
      "Using cached accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Using cached automated_interpretability-0.0.7-py3-none-any.whl (66 kB)\n",
      "Using cached babe-0.0.7-py3-none-any.whl (6.9 kB)\n",
      "Using cached beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "Using cached better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
      "Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached jaxtyping-0.2.38-py3-none-any.whl (56 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "Using cached plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Using cached pytest_profiling-1.8.1-py3-none-any.whl (9.9 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
      "Using cached simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Using cached typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Using cached wandb-0.19.6-py3-none-macosx_11_0_arm64.whl (19.9 MB)\n",
      "Using cached zstandard-0.22.0-cp311-cp311-macosx_11_0_arm64.whl (703 kB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Using cached blobfile-2.1.1-py3-none-any.whl (73 kB)\n",
      "Using cached boostedblob-0.15.6-py3-none-any.whl (59 kB)\n",
      "Using cached aiohttp-3.11.12-cp311-cp311-macosx_11_0_arm64.whl (455 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached orjson-3.10.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached pyarrow-19.0.0-cp311-cp311-macosx_12_0_arm64.whl (30.7 MB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl (24.8 MB)\n",
      "Using cached sentry_sdk-2.21.0-py2.py3-none-any.whl (324 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached statsmodels-0.14.4-cp311-cp311-macosx_11_0_arm64.whl (9.9 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached wadler_lindig-0.1.3-py3-none-any.whl (20 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached gprof2dot-2024.6.6-py2.py3-none-any.whl (34 kB)\n",
      "Using cached graze-0.1.29-py3-none-any.whl (19 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Using cached setproctitle-1.3.4-cp311-cp311-macosx_11_0_arm64.whl (11 kB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl (52 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached lxml-4.9.4-cp311-cp311-macosx_11_0_universal2.whl (8.6 MB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached pycryptodomex-3.21.0-cp36-abi3-macosx_10_9_universal2.whl (2.5 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl (92 kB)\n",
      "Using cached config2py-0.1.36-py3-none-any.whl (32 kB)\n",
      "Using cached dol-0.3.9-py3-none-any.whl (247 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached i2-0.1.46-py3-none-any.whl (202 kB)\n",
      "Installing collected packages: sentencepiece, pytz, mpmath, i2, dol, better-abc, zstandard, zipp, xxhash, wadler-lindig, uvloop, tzdata, typeguard, tqdm, threadpoolctl, tenacity, sympy, smmap, shellingham, setproctitle, sentry-sdk, safetensors, regex, pyzmq, python-dotenv, pydantic-core, pycryptodomex, pyarrow, protobuf, propcache, pluggy, orjson, numpy, networkx, multidict, mdurl, lxml, joblib, iniconfig, importlib_resources, gprof2dot, fsspec, frozenlist, filelock, fancy-einsum, einops, docstring-parser, docker-pycreds, dill, config2py, click, beartype, annotated-types, aiohappyeyeballs, yarl, torch, tiktoken, simple-parsing, scipy, pytest, pydantic, py2store, plotly, patsy, pandas, nltk, multiprocess, markdown-it-py, jaxtyping, importlib-metadata, huggingface-hub, httpx, graze, gitdb, blobfile, aiosignal, tokenizers, statsmodels, scikit-learn, rich, pytest-profiling, gitpython, circuitsvis, babe, aiohttp, accelerate, wandb, typer, transformers, plotly-express, boostedblob, transformers-stream-generator, datasets, automated-interpretability, transformer-lens, sae-lens\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 26.2.1\n",
      "    Uninstalling pyzmq-26.2.1:\n",
      "      Successfully uninstalled pyzmq-26.2.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "Successfully installed accelerate-1.3.0 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 annotated-types-0.7.0 automated-interpretability-0.0.7 babe-0.0.7 beartype-0.14.1 better-abc-0.0.3 blobfile-2.1.1 boostedblob-0.15.6 circuitsvis-1.43.3 click-8.1.8 config2py-0.1.36 datasets-2.21.0 dill-0.3.8 docker-pycreds-0.4.0 docstring-parser-0.16 dol-0.3.9 einops-0.8.1 fancy-einsum-0.0.3 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.6.1 gitdb-4.0.12 gitpython-3.1.44 gprof2dot-2024.6.6 graze-0.1.29 httpx-0.27.2 huggingface-hub-0.28.1 i2-0.1.46 importlib-metadata-8.6.1 importlib_resources-6.5.2 iniconfig-2.0.0 jaxtyping-0.2.38 joblib-1.4.2 lxml-4.9.4 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 nltk-3.9.1 numpy-1.26.4 orjson-3.10.15 pandas-2.2.3 patsy-1.0.1 plotly-5.24.1 plotly-express-0.4.1 pluggy-1.5.0 propcache-0.2.1 protobuf-5.29.3 py2store-0.1.20 pyarrow-19.0.0 pycryptodomex-3.21.0 pydantic-2.10.6 pydantic-core-2.27.2 pytest-8.3.4 pytest-profiling-1.8.1 python-dotenv-1.0.1 pytz-2025.1 pyzmq-26.0.0 regex-2024.11.6 rich-13.9.4 sae-lens-5.4.2 safetensors-0.4.5 scikit-learn-1.6.1 scipy-1.15.1 sentencepiece-0.2.0 sentry-sdk-2.21.0 setproctitle-1.3.4 shellingham-1.5.4 simple-parsing-0.1.7 smmap-5.0.2 statsmodels-0.14.4 sympy-1.13.3 tenacity-9.0.0 threadpoolctl-3.5.0 tiktoken-0.6.0 tokenizers-0.21.0 torch-2.4.1 tqdm-4.67.1 transformer-lens-2.14.0 transformers-4.48.3 transformers-stream-generator-0.0.5 typeguard-4.4.1 typer-0.12.5 tzdata-2025.1 uvloop-0.21.0 wadler-lindig-0.1.3 wandb-0.19.6 xxhash-3.5.0 yarl-1.18.3 zipp-3.21.0 zstandard-0.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # import google.colab # type: ignore\n",
    "    # from google.colab import output\n",
    "    %pip install sae-lens transformer-lens circuitsvis\n",
    "except:\n",
    "    from IPython import get_ipython  # type: ignore\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "uy-b3CcSOVHu",
    "outputId": "58ce28d0-f91f-436d-cf87-76bb26e2ecaf",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_lzma'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msae_lens\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LanguageModelSAERunnerConfig, SAETrainingRunner\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      7\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sae_lens/__init__.py:8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      6\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooked_sae_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HookedSAETransformer\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_activations_runner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CacheActivationsRunner\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     CacheActivationsRunnerConfig,\n\u001b[1;32m     12\u001b[0m     LanguageModelSAERunnerConfig,\n\u001b[1;32m     13\u001b[0m     PretokenizeRunnerConfig,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sae_lens/analysis/hooked_sae_transformer.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjaxtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Float\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mActivationCache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ActivationCache\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhook_points\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HookPoint  \u001b[38;5;66;03m# Hooking utilities\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHookedTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HookedTransformer\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/transformer_lens/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hook_points\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evals\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/transformer_lens/hook_points.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Slice, SliceInput\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLensHandle\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Dataclass that holds information about a PyTorch hook.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/transformer_lens/utils.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/datasets/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.21.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/datasets/arrow_dataset.py:76\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/datasets/arrow_reader.py:38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_path\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/datasets/utils/file_utils.py:49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtractManager\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrackedIterableFromGenerator\n\u001b[1;32m     53\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/datasets/utils/extract.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlzma\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/lzma.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _encode_filter_properties, _decode_filter_properties\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_compression\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_lzma'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "oe2nlqf-OVHv",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Model Selection and Evaluation (Feel Free to Skip)\n",
    "\n",
    "We'll use the runner to train an SAE on a TinyStories Model. This is a very small model so we can train an SAE on it quite quickly. Before we get started, let's load in the model with `transformer_lens` and see what it can do.\n",
    "\n",
    "TransformerLens gives us 2 functions that are useful here (and circuits viz provides a third):\n",
    "1. `transformer_lens.utils.test_prompt` will help us see when the model can infer one token.\n",
    "2. `HookedTransformer.generate` will help us see what happens when we sample from the model.\n",
    "3. `circuitsvis.logits.token_log_probs` will help us visualize the log probs of tokens at several positions in a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFz6JUMuOVHv"
   },
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-1L-21M\"\n",
    ")  # This will wrap huggingface models and has lots of nice utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUiXrjdUOVHv"
   },
   "source": [
    "### Getting a vibe for a model using `model.generate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZfKT5aDOVHv"
   },
   "source": [
    "Let's start by generating some stories using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4ad4Zz1OVHv"
   },
   "outputs": [],
   "source": [
    "# here we use generate to get 10 completeions with temperature 1. Feel free to play with the prompt to make it more interesting.\n",
    "for i in range(5):\n",
    "    display(\n",
    "        model.generate(\n",
    "            \"Once upon a time\",\n",
    "            stop_at_eos=False,  # avoids a bug on MPS\n",
    "            temperature=1,\n",
    "            verbose=False,\n",
    "            max_new_tokens=50,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDKr8o1xOVHv"
   },
   "source": [
    "One thing we notice is that the model seems to be able to repeat the name of the main character very consistently. It can output a pronoun intead but in some stories will repeat the protagonists name. This seems like an interesting capability to analyse with SAEs. To better understand the models ability to remember the protagonists name, let's extract a prompt where the next character is determined and use the \"test_prompt\" utility from TransformerLens to check the ranking of the token for that name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsfJX-YpOVHv"
   },
   "source": [
    "### Spot checking model abilities with `transformer_lens.utils.test_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpmPoj7uOVHv"
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "# Test the model with a prompt\n",
    "test_prompt(\n",
    "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little town. On her big adventure,\",\n",
    "    \" Lily\",\n",
    "    model,\n",
    "    prepend_space_to_answer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGzOvReDOVHv"
   },
   "source": [
    "In the output above, we see that the model assigns ~ 70% probability to \"she\" being the next token, and a 13% chance to \" Lily\" being the next token. Other names like Lucy or Anna are not highly ranked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QH8YOZOzOVHv"
   },
   "source": [
    "### Exploring Model Capabilities with Log Probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50mqTBihOVHw"
   },
   "source": [
    "Looking at token ranking for a single prompt is interesting, but a much higher through way to understand models is to look at token log probs for all tokens in text. We can use the `circuits_vis` package to get a nice visualization where we can see tokenization, and hover to get the top5 tokens by log probability. Darker tokens are tokens where the model assigned a higher probability to the actual next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tic0RCUpOVHw"
   },
   "outputs": [],
   "source": [
    "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
    "\n",
    "# Let's make a longer prompt and see the log probabilities of the tokens\n",
    "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")\n",
    "# hover on the output to see the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhGIl3YbOVHw"
   },
   "source": [
    "Let's combine `model.generate` and the token log probs visualization to see the log probs on text generated by the model. Note that we can play with the temperature and this should sample less likely trajectories according to the model. I've increased the maximum number of tokens in order to get a full story.\n",
    "\n",
    "Some things to explore:\n",
    "- Which tokens does the model assign high probability to? Can you see how the model should know which word comes next?\n",
    "- What happens if you increase / decrease the temperature?\n",
    "- Do the rankings of tokens seem sensible to you? What about where the model doesn't assign a high probability to the token which came next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nikp2ASlOVHw"
   },
   "outputs": [],
   "source": [
    "example_prompt = model.generate(\n",
    "    \"Once upon a time\",\n",
    "    stop_at_eos=False,  # avoids a bug on MPS\n",
    "    temperature=1,\n",
    "    verbose=True,\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "er3H1TDoOVHw"
   },
   "source": [
    "# Training an SAE\n",
    "\n",
    "Now we're ready to train out SAE. We'll make a runner config, instantiate the runner and the rest is taken care of for us!\n",
    "\n",
    "During training, you use weights and biases to check key metrics which indicate how well we are able to optimize the variables we care about.\n",
    "\n",
    "To get a better sense of which variables to look at, you can read my (Joseph's) post [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) and especially look at my weights and biases report [here](https://links-cdn.wandb.ai/wandb-public-images/links/jbloom/uue9i416.html).\n",
    "\n",
    "A few tips:\n",
    "- Feel free to reorganize your wandb dashboard to put L0, CE_Loss_score, explained variance and other key metrics in one section at the top.\n",
    "- Make a [run comparer](https://docs.wandb.ai/guides/app/features/panels/run-comparer) when tuning hyperparameters.\n",
    "- You can download the resulting sparse autoencoder / sparsity estimate from wandb and upload them to huggingface if you want to share your SAE with other.\n",
    "    - cfg.json (training config)\n",
    "    - sae_weight.safetensors (model weights)\n",
    "    - sparsity.safetensors (sparsity estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCHtPycOOVHw"
   },
   "source": [
    "## MLP Out\n",
    "\n",
    "I've tuned the hyperparameters below for a decent SAE which achieves 86% CE Loss recovered and an L0 of ~85, and runs in about 2 hours on an M3 Max. You can get an SAE that looks better faster if you only consider L0 and CE loss but it will likely have more dense features and more dead features. Here's a link to my output with two runs with two different L1's: https://wandb.ai/jbloom/sae_lens_tutorial ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAsZCAdJOVHw"
   },
   "outputs": [],
   "source": [
    "total_training_steps = 30_000  # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=\"expected_average_only_in\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khR_QkAJOVHw"
   },
   "source": [
    "# TO DO: Understanding TinyStories-1L with our SAE\n",
    "\n",
    "I haven't had time yet to complete this section, but I'd love to see a PR where someones uses an SAE they trained in this tutorial to understand this model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4sUumxZOVHw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's start by getting the top 10 logits for each feature\n",
    "projection_onto_unembed = sparse_autoencoder.W_dec @ model.W_U\n",
    "\n",
    "\n",
    "# get the top 10 logits.\n",
    "vals, inds = torch.topk(projection_onto_unembed, 10, dim=1)\n",
    "\n",
    "# get 10 random features\n",
    "random_indices = torch.randint(0, projection_onto_unembed.shape[0], (10,))\n",
    "\n",
    "# Show the top 10 logits promoted by those features\n",
    "top_10_logits_df = pd.DataFrame(\n",
    "    [model.to_str_tokens(i) for i in inds[random_indices]],\n",
    "    index=random_indices.tolist(),\n",
    ").T\n",
    "top_10_logits_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
